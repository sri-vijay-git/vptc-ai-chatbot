import os
import sys

# Configure UTF-8 encoding for Windows console
if sys.platform == 'win32':
    sys.stdout.reconfigure(encoding='utf-8')

# Add the parent directory (backend) to sys.path so we can import 'app' modules
sys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))

from app.services.pdf_service import pdf_service
from app.services.vector_store import vector_store

DOCUMENTS_DIR = "data/documents"

def ingest_documents():
    print("ğŸš€ Starting PDF Ingestion Process...")
    
    # Check if directory exists
    if not os.path.exists(DOCUMENTS_DIR):
        print(f"âŒ Documents directory not found at {DOCUMENTS_DIR}")
        print("Please create it and add your PDF files.")
        return

    files = [f for f in os.listdir(DOCUMENTS_DIR) if f.lower().endswith('.pdf')]
    
    if not files:
        print("âš ï¸  No PDF files found in data/documents/")
        return

    print(f"ğŸ“„ Found {len(files)} PDF details.")

    documents_content = []
    ids = []
    metadatas = []

    for filename in files:
        file_path = os.path.join(DOCUMENTS_DIR, filename)
        print(f"   scanning: {filename}...")
        
        # 1. Extract Text
        raw_text = pdf_service.extract_text_from_pdf(file_path)
        
        if not raw_text:
            print(f"   âš ï¸  Skipping empty file: {filename}")
            continue

        # 2. Chunk Text
        chunks = pdf_service.chunk_text(raw_text)
        print(f"     > Created {len(chunks)} chunks.")

        # 3. Prepare for Vector Store
        for i, chunk in enumerate(chunks):
            documents_content.append(chunk)
            ids.append(f"{filename}_{i}")
            metadatas.append({"source": filename, "chunk_index": i})

    if not documents_content:
        print("âŒ No valid text extracted from documents.")
        return

    print(f"ğŸ’¾ Stores {len(documents_content)} total chunks into ChromaDB...")
    
    # 4. Store in ChromaDB (Embeddings generated automatically inside add_documents)
    try:
        vector_store.add_documents(documents_content, metadatas, ids)
        print("âœ… Ingestion Complete! The chatbot is now trained on your documents.")
    except Exception as e:
        print(f"âŒ Error saving to database: {e}")

if __name__ == "__main__":
    ingest_documents()
